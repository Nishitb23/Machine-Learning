# -*- coding: utf-8 -*-
"""RBFnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mmLVFNe9RKO5djrzQhsB0oOhonebp899
"""

import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as fn
import torchvision
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import random

#load dataset and seperating features and labels
dataframe = pd.read_csv('heart_failure_clinical_records_dataset.csv')
features = dataframe.iloc[:, :-1].values
labels = dataframe.iloc[:, -1].values
x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=0)

#normalizing the data
s_scaler = StandardScaler()
x_train = s_scaler.fit_transform(x_train)
x_test = s_scaler.transform(x_test)
center_id = random.sample(range(200), 3)
centers = torch.tensor(x_train[center_id])
print(centers)
#converting data arrays to tensors
x_train = torch.tensor(x_train)
y_train = torch.tensor(y_train)
x_test = torch.tensor(x_test)
y_test = torch.tensor(y_test)

class RBFnet(nn.Module):
  def __init__(self,centers):
    super(RBFnet, self).__init__()
    self.n_input = 12
    self.n_output = 1
    self.n_rbf = 3
    self.centers = nn.Parameter(centers)
    self.denom = nn.Parameter(torch.ones(1,self.n_rbf)) #let denom = 1/(2*sigma^2)
    self.linear = nn.Linear(self.n_rbf, self.n_output)
  def forward(self,input):
    rbf_output = torch.exp(torch.sum(-((self.centers - input)**2),1)*self.denom)
    prediction = self.linear(rbf_output.float())
    return prediction

def train(model,input,label,loss_fn,optimizer):
  optimizer.zero_grad()
  predict = model(input).float()
  if label == 0:
    label = torch.tensor([0])
  else:
    label = torch.tensor([10])
  label = label.float()
  loss = loss_fn(label, predict[0])
  loss.backward()
  optimizer.step()
  return predict,loss.item()

def test(model,input,label,loss_fn):
  predict = model(input)
  if label == 0:
    label = torch.tensor([0])
  else:
    label = torch.tensor([10])
  loss = loss_fn(label.float(), predict.float()[0])
  return predict,loss.item()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
loss_fn = nn.MSELoss()
learning_rates = [1e-3]
epochs = [10,20,30,40,50,60,70,80,90,100]
epochs = [1]
training_loss = []
accuracy = []
test_loss = []
model = RBFnet(centers).to(device)
for learning_rate in learning_rates:
  for epoch in epochs:
    #model = RBFnet(centers).to(device)
    tn_loss = 0
    for e in range(epoch):
      tn_loss = 0
      for i in range(len(x_train)):
        optimizer = optim.Adam(model.parameters(), lr= learning_rate)
        predict, loss = train(model,x_train[i],y_train[i],loss_fn,optimizer)
        tn_loss = tn_loss + loss
    training_loss.append(tn_loss/len(x_train))
    tt_loss = 0
    for i in range(len(x_test)):
      predict,loss = test(model,x_test[i],y_test[i],loss_fn)
      tt_loss = tt_loss + loss
      if(predict>0):
        print("prediction: 1",predict,y_test[i])
      else:
        print("prediction: 0",predict,y_test[i])
    test_loss.append(tt_loss/len(x_test))

print(training_loss)
print(test_loss)

